{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fast_tfai.utils.console import console\n",
    "from fast_tfai.utils.validate_args import DatasetConf\n",
    "\n",
    "VALID_FORMATS = [\"csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(repr=False)\n",
    "class MultiLabelDataset:\n",
    "    df: pd.DataFrame\n",
    "    train_df: pd.DataFrame = field(default=None)\n",
    "    val_df: pd.DataFrame = field(default=None)\n",
    "    test_df: pd.DataFrame = field(default=None)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Get class names and number of classes\n",
    "        self.class_names = sorted([x[1] for x in self.df.columns if x[0] == \"class\"])\n",
    "        self.num_classes = len(self.class_names)\n",
    "\n",
    "        # Maps class2int and int2class\n",
    "        label_int = [str(x) for x in range(len(self.class_names))]\n",
    "        self.class2int_map = dict(zip(self.class_names, label_int))\n",
    "        self.int2class_map = {v: k for k, v in self.class2int_map.items()}\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        out_str = f\"Dataset(df: {self.df.shape[0]}\"\n",
    "        if (\n",
    "            self.train_df is not None\n",
    "            and self.test_df is not None\n",
    "            and self.val_df is not None\n",
    "        ):\n",
    "            out_str += (\n",
    "                f\", train_df: {self.train_df.shape[0]}, \"\n",
    "                f\"val_df: {self.val_df.shape[0]}, test_df: {self.test_df.shape[0]}\"\n",
    "            )\n",
    "        return out_str + \")\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build_df(\n",
    "        images_list: List[Path],\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Extract filenames and labels (based on the path).\n",
    "\n",
    "        Args:\n",
    "            images_list (List[Path]): a list containing all the filenames of the images.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: a pandas DataFrame of the filenames and the list of the labels.\n",
    "                The labels are inferred from the name of the last directory in the path.\n",
    "        \"\"\"\n",
    "        filenames = [str(x) for x in images_list]\n",
    "        labels = [x.parts[-2] for x in images_list]\n",
    "        return pd.DataFrame({\"filename\": filenames, \"label\": labels})\n",
    "\n",
    "    @classmethod\n",
    "    def from_conf(cls, conf: DatasetConf):\n",
    "        if conf.format not in VALID_FORMATS:\n",
    "            raise ValueError(f\"dataset 'format' must be in {VALID_FORMATS}\")\n",
    "\n",
    "        return cls.from_df(file_path=conf.path, splitted=conf.is_splitted)\n",
    "\n",
    "    @classmethod\n",
    "    def from_df(cls, file_path: Union[Path, str], splitted: bool = False):\n",
    "        file_path = Path(file_path)\n",
    "        if splitted:\n",
    "            train_df = pd.read_csv(file_path / \"train.csv\")\n",
    "            val_df = pd.read_csv(file_path / \"val.df\")\n",
    "            test_df = pd.read_csv(file_path / \"test.df\")\n",
    "            df = pd.concat([train_df, val_df, test_df])\n",
    "            dataset = MultiLabelDataset(df)\n",
    "            dataset.train_df = train_df\n",
    "            dataset.val_df = val_df\n",
    "            dataset.test_df = test_df\n",
    "            dataset._add_label_int()\n",
    "        else:\n",
    "            df: pd.DataFrame = pd.read_csv(file_path / \"dataset.csv\", header=[0, 1])\n",
    "            dataset = MultiLabelDataset(df)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def to_csv(self, output_path: Union[str, Path]):\n",
    "        \"\"\"Write the dataset to csv files.\n",
    "\n",
    "        Args:\n",
    "            output_path (Union[str, Path]): a string or a Path for the output folder.\n",
    "        \"\"\"\n",
    "        output_path = Path(output_path)\n",
    "        self.df.to_csv(str(output_path / \"df.csv\"), index=False)\n",
    "        if self.train_df is not None:\n",
    "            self.train_df.to_csv(str(output_path / \"train.csv\"), index=False)\n",
    "        if self.val_df is not None:\n",
    "            self.val_df.to_csv(str(output_path / \"val.csv\"), index=False)\n",
    "        if self.test_df is not None:\n",
    "            self.test_df.to_csv(str(output_path / \"test.csv\"), index=False)\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"Print a summary with some stats about the dataset.\"\"\"\n",
    "        console.rule(\"[bold red] Dataset Summary\")\n",
    "        console.print()\n",
    "        console.print(f\"Dataset size: {self.df.shape[0]}\")\n",
    "        console.print(\"Dataset distribution:\")\n",
    "\n",
    "        console.print(np.sum(self.df[\"class\"]), \"\\n\")\n",
    "\n",
    "        if (\n",
    "            (self.train_df is not None)\n",
    "            and (self.val_df is not None)\n",
    "            and (self.test_df is not None)\n",
    "        ):\n",
    "            console.print(f\"Train size: {self.train_df.shape[0]}\")\n",
    "            console.print(\"Train distribution:\")\n",
    "            console.print(np.sum(self.train_df[\"class\"]), \"\\n\")\n",
    "            console.print(f\"Validation size: {self.val_df.shape[0]}\")\n",
    "            console.print(\"Validation distribution:\")\n",
    "            console.print(np.sum(self.val_df[\"class\"]), \"\\n\")\n",
    "            console.print(f\"Test size: {self.test_df.shape[0]}\")\n",
    "            console.print(\"Test distribution:\")\n",
    "            console.print(np.sum(self.test_df[\"class\"]), \"\\n\")\n",
    "        console.rule()\n",
    "\n",
    "    def split(\n",
    "        self,\n",
    "        test_size: float = 0.2,\n",
    "        validation_size: float = 0.1,\n",
    "        seed: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"Split the dataset into train, val and test. Only stratified splitting\n",
    "            based on the 'label' column.\n",
    "\n",
    "        Args:\n",
    "            test_size (float, optional): test size in percentage in (0, 1). Defaults to 0.2.\n",
    "            validation_size (float, optional): validation size in percentage in (0, 1).\n",
    "                Defaults to 0.1.\n",
    "            seed (Optional[int], optional): set the random number generator seed.\n",
    "                Defaults to None.\n",
    "        \"\"\"\n",
    "\n",
    "        from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "        msss = MultilabelStratifiedShuffleSplit(\n",
    "            n_splits=1, test_size=test_size, random_state=seed\n",
    "        )\n",
    "\n",
    "        msss2 = MultilabelStratifiedShuffleSplit(\n",
    "            n_splits=1, test_size=validation_size, random_state=seed\n",
    "        )\n",
    "\n",
    "        X, y = self.df[\"image\"].to_numpy(), self.df[\"class\"].to_numpy()\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        for train_index, test_index in msss.split(X, y):\n",
    "            X_train, X_test = X[train_index, :], X[test_index, :]\n",
    "            y_train, y_test = y[train_index, :], y[test_index, :]\n",
    "\n",
    "        for train_index, test_index in msss2.split(X_train, y_train):\n",
    "            X_train, X_val = (\n",
    "                X_train[train_index, :],\n",
    "                X_train[test_index, :],\n",
    "            )\n",
    "            y_train, y_val = (\n",
    "                y_train[train_index, :],\n",
    "                y_train[test_index, :],\n",
    "            )\n",
    "\n",
    "        self.train_df = pd.concat(\n",
    "            [pd.DataFrame(X_train), pd.DataFrame(y_train)], axis=1\n",
    "        )\n",
    "        self.val_df = pd.concat([pd.DataFrame(X_val), pd.DataFrame(y_val)], axis=1)\n",
    "        self.test_df = pd.concat([pd.DataFrame(X_test), pd.DataFrame(y_test)], axis=1)\n",
    "\n",
    "        self.train_df.columns = self.df.columns\n",
    "        self.val_df.columns = self.df.columns\n",
    "        self.test_df.columns = self.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/simone/workspace/fast-tfai/resources/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mld = MultiLabelDataset.from_df(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mld.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mld.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mld.train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mld.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/home/simone/workspace/fast-tfai/resources/dataset.csv\", header=[0, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"/home/simone/workspace/dataset-registry/images/SSS/ST4/\"\n",
    "df[(\"image\", \"path\")] = df[(\"image\", \"path\")].apply(lambda x: prefix + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/simone/workspace/fast-tfai/resources/dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast-tfai-SRYBve37-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
