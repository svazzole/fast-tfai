{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tf2onnx\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = \"/home/simone/workspace/fogna/datasets/ompi/SJZ4_HangClip/bad/\"\n",
    "images_format = \"*.tiff\"\n",
    "model_folder = (\n",
    "    \"/home/simone/workspace/fogna/outputs/ompi/sjz4/cocky_euler_9fb06172/keras\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = Path(images_folder)\n",
    "images_list = list(images_path.rglob(images_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_folder)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_heatmap(model):\n",
    "    last_conv_layer = model.layers[-2].layers[-2].get_output_at(0)\n",
    "    weights = model.layers[-1].get_weights()[0]\n",
    "\n",
    "    backbone_conv_model = tf.keras.Model(\n",
    "        inputs=model.layers[-2].input, outputs=[last_conv_layer]\n",
    "    )\n",
    "\n",
    "    new_inputs = tf.keras.layers.Input(shape=model.input.shape[1:])\n",
    "    conv_layer = backbone_conv_model(new_inputs)\n",
    "    new_model = tf.keras.Model(inputs=new_inputs, outputs=[conv_layer], name=\"castrato\")\n",
    "\n",
    "    new_input = tf.keras.layers.Input(shape=model.input.shape[1:])\n",
    "    pred = model(new_input)\n",
    "    conv = new_model(new_input)\n",
    "    pred_class = tf.math.argmax(pred, axis=1)\n",
    "\n",
    "    reshaped_w = tf.expand_dims(weights, axis=0)\n",
    "    class_weights = tf.transpose(\n",
    "        tf.gather(reshaped_w, pred_class, axis=2), perm=[2, 1, 0]\n",
    "    )\n",
    "\n",
    "    output = tf.matmul(conv, class_weights)\n",
    "\n",
    "    # output = tf.einsum(\"bijc,bck->bijk\", heatmaps, class_weights)\n",
    "    heatmaps = tf.image.resize(output, model.input.shape[1:3], method=\"bilinear\")\n",
    "\n",
    "    return tf.keras.Model(new_input, [pred, heatmaps])\n",
    "\n",
    "    # last_conv_layer = model.layers[-2].layers[-2].get_output_at(0)\n",
    "    # weights = model.layers[-1].get_weights()[0]\n",
    "\n",
    "    # backbone_conv_model = tf.keras.Model(inputs=model.layers[-2].input, outputs=[last_conv_layer])\n",
    "\n",
    "    # new_inputs = tf.keras.layers.Input(shape=model.input.shape[1:])\n",
    "    # conv_layer = backbone_conv_model(new_inputs)\n",
    "    # new_model = tf.keras.Model(inputs=new_inputs, outputs=[conv_layer], name=\"castrato\")\n",
    "\n",
    "    # new_input = tf.keras.layers.Input(shape=model.input.shape[1:])\n",
    "    # pred = model(new_input)  # [0]\n",
    "    # # print(pred.shape)\n",
    "    # conv = new_model(new_input)\n",
    "    # pred_class = tf.math.argmax(pred, axis=1)\n",
    "    # print(pred_class.shape)\n",
    "    # # print(weights.shape)\n",
    "    # reshaped_w = tf.expand_dims(weights, axis=0)\n",
    "    # # print(reshaped_w.shape)\n",
    "    # # tiled_weights = tf.tile(reshaped_w, [tf.shape(new_input)[0], 1, 1])\n",
    "    # # print(tiled_weights.shape)\n",
    "    # # class_weights = tf.gather(tiled_weights, pred_class, axis=2)[:, :, 0]\n",
    "    # class_weights = tf.transpose(tf.gather(reshaped_w, pred_class, axis=2), perm=[2, 1, 0])\n",
    "    # # class_weights = tf.squeeze(class_weights, axis=2)\n",
    "    # print(class_weights.shape)\n",
    "\n",
    "    # heatmaps = tf.image.resize(\n",
    "    #     conv, model.input.shape[1:3], method=\"bilinear\"\n",
    "    # )\n",
    "\n",
    "    # print(heatmaps)\n",
    "\n",
    "    # # output = tf.tensordot(\n",
    "    # #     heatmaps,\n",
    "    # #     class_weights,\n",
    "    # #     axes=[[3], [1]],\n",
    "    # # )# [:, :, :, 0, 0]\n",
    "\n",
    "    # output = tf.einsum(\"bijc,bck->bijk\", heatmaps, class_weights)\n",
    "    # # output = tf.matmul(heatmaps, class_weights)\n",
    "\n",
    "    # return tf.keras.Model(new_input, [pred, output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer = model.layers[-2].layers[-2].get_output_at(0)\n",
    "weights = model.layers[-1].get_weights()[0]\n",
    "\n",
    "backbone_conv_model = tf.keras.Model(\n",
    "    inputs=model.layers[-2].input, outputs=[last_conv_layer]\n",
    ")\n",
    "\n",
    "new_inputs = tf.keras.layers.Input(shape=model.input.shape[1:])\n",
    "conv_layer = backbone_conv_model(new_inputs)\n",
    "new_model = tf.keras.Model(inputs=new_inputs, outputs=[conv_layer], name=\"castrato\")\n",
    "\n",
    "new_input = tf.keras.layers.Input(shape=model.input.shape[1:])\n",
    "pred = model(new_input)\n",
    "conv = new_model(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = tf.math.argmax(pred, axis=1)\n",
    "reshaped_w = tf.reshape(weights, [-1, *weights.shape])\n",
    "tmp = tf.gather(reshaped_w, pred_class, axis=2)\n",
    "class_weights = tf.transpose(tmp, perm=[2, 1, 0])\n",
    "\n",
    "output = tf.einsum(\n",
    "    \"bijc,bck->bijk\", conv, class_weights\n",
    ")  # tf.matmul(conv, class_weights)\n",
    "heatmaps = tf.image.resize(\n",
    "    output, model.input.shape[1:3], method=\"bilinear\", name=\"heatmap\"\n",
    ")\n",
    "heatmaps = tf.cast(\n",
    "    (heatmaps - tf.reduce_min(heatmaps, axis=[1, 2], keepdims=True))\n",
    "    / (tf.reduce_max(heatmaps) - tf.reduce_min(heatmaps, axis=[1, 2], keepdims=True))\n",
    "    * 255,\n",
    "    dtype=tf.uint8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_heat = tf.keras.Model(new_input, [pred, heatmaps])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_file = (\n",
    "    \"/home/simone/workspace/fogna/outputs/ompi/sjz4/cocky_euler_9fb06172/test.csv\"\n",
    ")\n",
    "test_df = pd.read_csv(test_df_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagenerator = tfk.preprocessing.image.ImageDataGenerator()\n",
    "test_data = test_datagenerator.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(448, 448),\n",
    "    batch_size=32,\n",
    "    seed=171717,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_data, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lbl = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred_lbl)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_true=y_true, y_pred=y_pred_lbl, digits=4)\n",
    "print(cr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = attach_heatmap(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = model_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 13\n",
    "img = cv2.imread(str(images_list[i]), cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "\n",
    "heat = final_model(img[np.newaxis, ...])\n",
    "\n",
    "print(heat[0][0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 9))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(img)\n",
    "ax[1].imshow(heat[1][0, :], cmap=\"jet\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 13\n",
    "img1 = cv2.imread(str(images_list[i]), cv2.IMREAD_COLOR)\n",
    "img2 = cv2.imread(str(images_list[i + 1]), cv2.IMREAD_COLOR)\n",
    "# img3 = cv2.imread(str(images_list[i+2]), cv2.IMREAD_COLOR)\n",
    "img1 = cv2.resize(img1, (224, 224))\n",
    "img2 = cv2.resize(img2, (224, 224))\n",
    "# img3 = cv2.resize(img3, (224, 224))\n",
    "\n",
    "img = np.stack([img1, img2])\n",
    "\n",
    "# img = np.stack([img1, img2, img3])\n",
    "\n",
    "heat = final_model(img)\n",
    "\n",
    "print(heat[0])\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 9))\n",
    "ax[0][0].imshow(img[0, :])\n",
    "ax[0][1].imshow(img[0, :])\n",
    "ax[0][1].imshow(heat[1][0, :], cmap=\"jet\", alpha=0.5)\n",
    "ax[1][0].imshow(img[1, :])\n",
    "ax[1][1].imshow(img[1, :])\n",
    "ax[1][1].imshow(heat[1][1, :], cmap=\"jet\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signature = [\n",
    "    tf.TensorSpec([None, *model.input_shape[1:]], tf.float32, name=\"inputs\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opset = 13\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(final_model, input_signature, opset=opset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(onnx_model, \"heatmap.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = rt.InferenceSession(\"heatmap.onnx\", providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, i in enumerate(session.get_inputs()):\n",
    "    print(f\"input {ix}: {i}\")\n",
    "\n",
    "for ix, i in enumerate(session.get_outputs()):\n",
    "    print(f\"output {ix}: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.array(img, dtype=np.float32)\n",
    "inputs = {\"inputs\": inp[np.newaxis, ...]}\n",
    "outputs = session.run(None, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.imshow(outputs[1][0], cmap=\"jet\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.array(img, dtype=np.float32)\n",
    "inputs = {\"inputs\": inp[np.newaxis, ...]}\n",
    "st = time.time()\n",
    "outputs = session.run(None, inputs)\n",
    "print(f\"elapsed time: {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"/home/simone/workspace/fogna/outputs/ompi/sjz4/cocky_euler_9fb06172/onnx/cocky_euler_9fb06172.onnx\"\n",
    "session = rt.InferenceSession(model_folder, providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.array(img, dtype=np.float32)\n",
    "inputs = {\"inputs\": inp[np.newaxis, ...]}\n",
    "st = time.time()\n",
    "outputs = session.run(None, inputs)\n",
    "print(f\"elapsed time: {time.time() - st}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = rt.InferenceSession(\"heatmap.onnx\", providers=[\"CUDAExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 34\n",
    "img = cv2.imread(str(images_list[i]), cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "inp = np.array(img, dtype=np.float32)\n",
    "inputs = {\"inputs\": inp[np.newaxis, ...]}\n",
    "st = time.time()\n",
    "outputs = session.run(None, inputs)\n",
    "print(f\"elapsed time: {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast-tfai-SRYBve37-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "dda41536bdf11d970e0ebbbb3ecc38ed7d8f751ba637ba03499ce81090dd9060"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
